{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from development.datasets.osdg_dataset import load_osdg_data\n",
    "from development.datasets.uclmodules_dataset import load_uclmodules_data\n",
    "from development.datasets.videscription_dataset import load_videscription_data\n",
    "from development.datasets.relx_dataset import load_relx_data\n",
    "from development.models.Bert import Bert\n",
    "from development.models.BertMultiLabel import BertMultiLabel\n",
    "from development.models.RobertaNER import RobertaNER\n",
    "from development.train_model import fine_tune_transformer\n",
    "from development.pipelines import full_pipe\n",
    "from development.scrape.RelxScraper import RelxScraper\n",
    "from development.utils import parse_sdg_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json', 'r') as file:\n",
    "    CONFIG = json.load(file)\n",
    "    dev_config = CONFIG['development']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "osdg_data = load_osdg_data(\n",
    "    dev_config['osdg_data_path'],\n",
    "    training=False,\n",
    "    filter_agreement=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sdg\n",
       "1     2734\n",
       "2     2457\n",
       "3     2689\n",
       "4     3740\n",
       "5     4338\n",
       "6     2815\n",
       "7     3048\n",
       "8     1509\n",
       "9     2105\n",
       "10    2032\n",
       "11    2277\n",
       "12    1108\n",
       "13    2102\n",
       "14    1141\n",
       "15    2143\n",
       "16    5451\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osdg_data.groupby(['sdg']).count()['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "osdg_data = load_osdg_data(\n",
    "    dev_config['osdg_data_path'],\n",
    "    training=True,\n",
    "    filter_agreement=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucl_data = load_uclmodules_data(dev_config['uclmodules_data_path'], only_labled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "videscription_data = load_videscription_data(\n",
    "    dev_config['videscription_data_path']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = Bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = fine_tune_transformer(\n",
    "    bert.model,\n",
    "    bert.tokenizer,\n",
    "    bert.tokenizer_args,\n",
    "    data=osdg_data,\n",
    "    dev_config=dev_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = Bert('./development/weights/Bert-5/checkpoint-6384/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89      1914\n",
      "           1       0.90      0.94      0.92      1720\n",
      "           2       0.96      0.97      0.96      1882\n",
      "           3       0.95      0.97      0.96      2618\n",
      "           4       0.96      0.95      0.95      3037\n",
      "           5       0.92      0.93      0.93      1970\n",
      "           6       0.94      0.95      0.94      2134\n",
      "           7       0.88      0.82      0.85      1056\n",
      "           8       0.91      0.92      0.91      1473\n",
      "           9       0.89      0.80      0.84      1422\n",
      "          10       0.93      0.95      0.94      1594\n",
      "          11       0.92      0.93      0.92       776\n",
      "          12       0.93      0.94      0.94      1471\n",
      "          13       0.97      0.92      0.95       799\n",
      "          14       0.95      0.91      0.93      1500\n",
      "          15       1.00      1.00      1.00      3816\n",
      "\n",
      "    accuracy                           0.94     29182\n",
      "   macro avg       0.93      0.92      0.93     29182\n",
      "weighted avg       0.94      0.94      0.94     29182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls_report = bert.evaluate(osdg_data['train'])\n",
    "print(cls_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A matching Triton is not available, some optimizations will not be enabled.\n",
      "Error caught was: No module named 'triton'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91       410\n",
      "           1       0.92      0.95      0.94       368\n",
      "           2       0.94      0.98      0.96       403\n",
      "           3       0.95      0.96      0.96       561\n",
      "           4       0.96      0.94      0.95       650\n",
      "           5       0.92      0.97      0.94       422\n",
      "           6       0.94      0.93      0.94       457\n",
      "           7       0.82      0.80      0.81       227\n",
      "           8       0.90      0.91      0.91       316\n",
      "           9       0.92      0.78      0.84       305\n",
      "          10       0.94      0.96      0.95       342\n",
      "          11       0.94      0.92      0.93       166\n",
      "          12       0.94      0.96      0.95       316\n",
      "          13       0.97      0.91      0.94       171\n",
      "          14       0.94      0.93      0.93       322\n",
      "          15       0.99      1.00      1.00       817\n",
      "\n",
      "    accuracy                           0.94      6253\n",
      "   macro avg       0.93      0.93      0.93      6253\n",
      "weighted avg       0.94      0.94      0.94      6253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls_report = bert.evaluate(osdg_data['valid'])\n",
    "print(cls_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89       410\n",
      "           1       0.93      0.96      0.94       369\n",
      "           2       0.95      0.98      0.96       404\n",
      "           3       0.94      0.96      0.95       561\n",
      "           4       0.95      0.93      0.94       651\n",
      "           5       0.91      0.94      0.93       423\n",
      "           6       0.96      0.95      0.95       457\n",
      "           7       0.88      0.81      0.84       226\n",
      "           8       0.94      0.93      0.93       316\n",
      "           9       0.90      0.79      0.84       305\n",
      "          10       0.94      0.95      0.94       341\n",
      "          11       0.93      0.90      0.92       166\n",
      "          12       0.91      0.94      0.92       315\n",
      "          13       0.98      0.96      0.97       171\n",
      "          14       0.94      0.92      0.93       321\n",
      "          15       1.00      1.00      1.00       818\n",
      "\n",
      "    accuracy                           0.94      6254\n",
      "   macro avg       0.93      0.93      0.93      6254\n",
      "weighted avg       0.94      0.94      0.94      6254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls_report = bert.evaluate(osdg_data['test'])\n",
    "print(cls_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model = RobertaNER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORG: The World Resources Institute\n",
      "ORG: World Resources Institute\n"
     ]
    }
   ],
   "source": [
    "ner_model.print_entities(osdg_data['train'][0][14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>SDG</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is why the Sustainable Development of Protected Areas System of Ethiopia was set up, with support from the Global Environment Fund and UNDP. The project is spearheading a suite of interventions, focusing on the national system in terms of capacity building and training, and integrating the protected area system into mainstream development. Since the initiation of the project in 2008, valuation exercises have found that the main value of protected areas is in the environmental services that they provide to poor rural communities, many of which are food-insecure, protected areas were incorporated into the Ethiopia Poverty Strategy, and the legal boundaries of the protected area system were strengthened by supporting the demarcation and gazettement of four areas through a highly consultative process (UNDP, n.d.).</td>\n",
       "      <td>Climate Action</td>\n",
       "      <td>ORG: the Sustainable Development of Protected Areas System of Ethiopia - ORG: the Global Environment Fund - ORG: UNDP - ORG: UNDP -</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Text  \\\n",
       "0  This is why the Sustainable Development of Protected Areas System of Ethiopia was set up, with support from the Global Environment Fund and UNDP. The project is spearheading a suite of interventions, focusing on the national system in terms of capacity building and training, and integrating the protected area system into mainstream development. Since the initiation of the project in 2008, valuation exercises have found that the main value of protected areas is in the environmental services that they provide to poor rural communities, many of which are food-insecure, protected areas were incorporated into the Ethiopia Poverty Strategy, and the legal boundaries of the protected area system were strengthened by supporting the demarcation and gazettement of four areas through a highly consultative process (UNDP, n.d.).   \n",
       "\n",
       "              SDG  \\\n",
       "0  Climate Action   \n",
       "\n",
       "                                                                                                                               Entities  \\\n",
       "0  ORG: the Sustainable Development of Protected Areas System of Ethiopia - ORG: the Global Environment Fund - ORG: UNDP - ORG: UNDP -    \n",
       "\n",
       "  Sentiment  \n",
       "0      NULL  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = full_pipe(bert, ner_model, texts=[osdg_data['train'][0][7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "relx_scraper = RelxScraper()\n",
    "relx_scraper.scrape_data(start=0)\n",
    "relx_scraper.save_as_csv('./data/relx_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "relx_training_data = load_relx_data(\n",
    "    data_path=dev_config['relx_data_path'],\n",
    "    training=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_multilabel = BertMultiLabel(\n",
    "    './development/weights/Bert-5/checkpoint-6384/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = fine_tune_transformer(\n",
    "    bert_multilabel.model,\n",
    "    bert_multilabel.tokenizer,\n",
    "    bert_multilabel.tokenizer_args,\n",
    "    data=relx_training_data,\n",
    "    dataset='relx',\n",
    "    dev_config=dev_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_multilabel = BertMultiLabel(\n",
    "    './development/weights/Bert-Multilabel-5/checkpoint-1400/'\n",
    ")\n",
    "bert_multilabel.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.36      0.53        14\n",
      "           1       0.91      0.96      0.94        77\n",
      "           2       0.99      0.93      0.96       543\n",
      "           3       1.00      0.61      0.76        23\n",
      "           4       0.98      0.89      0.93        53\n",
      "           5       0.97      0.93      0.95        99\n",
      "           6       0.90      0.88      0.89        42\n",
      "           7       1.00      0.33      0.50        21\n",
      "           8       0.80      0.69      0.74        51\n",
      "           9       0.95      0.62      0.75       166\n",
      "          10       0.99      0.83      0.90        99\n",
      "          11       0.90      0.70      0.79        61\n",
      "          12       0.99      0.83      0.90       222\n",
      "          13       0.98      0.87      0.92        54\n",
      "          14       0.80      0.84      0.82        77\n",
      "          15       0.68      0.48      0.57        27\n",
      "\n",
      "   micro avg       0.95      0.83      0.89      1629\n",
      "   macro avg       0.93      0.73      0.80      1629\n",
      "weighted avg       0.96      0.83      0.88      1629\n",
      " samples avg       0.96      0.87      0.90      1629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls_report = bert_multilabel.evaluate(relx_training_data['train'])\n",
    "print(cls_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00         1\n",
      "           1       0.71      0.83      0.77        12\n",
      "           2       0.92      0.86      0.89        98\n",
      "           3       0.75      0.60      0.67         5\n",
      "           4       0.60      0.33      0.43         9\n",
      "           5       0.60      0.75      0.67        16\n",
      "           6       0.60      0.43      0.50         7\n",
      "           7       1.00      0.00      0.00         1\n",
      "           8       0.33      0.38      0.35         8\n",
      "           9       0.85      0.48      0.61        23\n",
      "          10       0.67      0.50      0.57        12\n",
      "          11       0.50      0.33      0.40        12\n",
      "          12       0.87      0.60      0.71        43\n",
      "          13       0.75      0.60      0.67         5\n",
      "          14       0.47      0.54      0.50        13\n",
      "          15       0.50      0.40      0.44         5\n",
      "\n",
      "   micro avg       0.77      0.66      0.71       270\n",
      "   macro avg       0.69      0.48      0.51       270\n",
      "weighted avg       0.78      0.66      0.70       270\n",
      " samples avg       0.81      0.71      0.72       270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls_report = bert_multilabel.evaluate(relx_training_data['valid'])\n",
    "print(cls_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00         1\n",
      "           1       0.79      0.73      0.76        15\n",
      "           2       0.97      0.85      0.90       100\n",
      "           3       1.00      0.00      0.00         6\n",
      "           4       0.75      0.60      0.67        10\n",
      "           5       0.91      0.83      0.87        12\n",
      "           6       0.70      0.70      0.70        10\n",
      "           7       1.00      0.00      0.00         4\n",
      "           8       0.17      0.12      0.14         8\n",
      "           9       0.62      0.45      0.52        29\n",
      "          10       0.40      0.27      0.32        15\n",
      "          11       0.67      0.40      0.50        10\n",
      "          12       0.89      0.63      0.74        38\n",
      "          13       0.89      0.80      0.84        10\n",
      "          14       0.60      0.50      0.55        12\n",
      "          15       1.00      0.29      0.44         7\n",
      "\n",
      "   micro avg       0.82      0.63      0.71       287\n",
      "   macro avg       0.77      0.45      0.50       287\n",
      "weighted avg       0.81      0.63      0.69       287\n",
      " samples avg       0.87      0.73      0.76       287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls_report = bert_multilabel.evaluate(relx_training_data['test'])\n",
    "print(cls_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A matching Triton is not available, some optimizations will not be enabled.\n",
      "Error caught was: No module named 'triton'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.61      0.74       410\n",
      "           1       0.92      0.88      0.90       369\n",
      "           2       0.62      0.99      0.76       404\n",
      "           3       0.92      0.90      0.91       561\n",
      "           4       0.93      0.89      0.91       651\n",
      "           5       0.91      0.85      0.88       423\n",
      "           6       0.97      0.81      0.88       457\n",
      "           7       0.84      0.64      0.72       226\n",
      "           8       0.90      0.84      0.87       316\n",
      "           9       0.51      0.87      0.65       305\n",
      "          10       0.78      0.93      0.84       341\n",
      "          11       0.97      0.61      0.75       166\n",
      "          12       0.71      0.91      0.80       315\n",
      "          13       0.96      0.87      0.91       171\n",
      "          14       0.90      0.88      0.89       321\n",
      "          15       1.00      0.82      0.90       818\n",
      "\n",
      "    accuracy                           0.84      6254\n",
      "   macro avg       0.86      0.83      0.83      6254\n",
      "weighted avg       0.87      0.84      0.85      6254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls_report = bert_multilabel.evaluate_single_label(\n",
    "    osdg_data['test'],\n",
    "    mode='exact_match'\n",
    ")\n",
    "print(cls_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9267668692037097"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = bert_multilabel.evaluate_single_label(\n",
    "    osdg_data['test'],\n",
    "    mode='included'\n",
    ")\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucl_data = load_uclmodules_data(\n",
    "    dev_config['uclmodules_data_path'],\n",
    "    only_labled=True,\n",
    "    evaluation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.09      0.16        87\n",
      "           1       0.30      0.58      0.40        12\n",
      "           2       0.84      0.90      0.87      1015\n",
      "           3       0.17      0.88      0.29       258\n",
      "           4       0.37      0.72      0.49       128\n",
      "           5       0.26      0.83      0.40        18\n",
      "           6       0.62      0.62      0.62        76\n",
      "           7       0.70      0.35      0.47       339\n",
      "           8       0.62      0.67      0.64       588\n",
      "           9       0.07      0.60      0.13        53\n",
      "          10       0.68      0.42      0.52       506\n",
      "          11       0.10      0.33      0.16        24\n",
      "          12       0.26      0.74      0.39        68\n",
      "          13       0.58      0.55      0.56        20\n",
      "          14       0.21      0.67      0.32        18\n",
      "          15       0.66      0.62      0.64       667\n",
      "\n",
      "   micro avg       0.48      0.66      0.56      3877\n",
      "   macro avg       0.45      0.60      0.44      3877\n",
      "weighted avg       0.64      0.66      0.61      3877\n",
      " samples avg       0.56      0.69      0.58      3877\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls_report = bert_multilabel.evaluate(ucl_data)\n",
    "print(cls_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Cardiac Critical Care (CHLD0081) \\n Summary\\nThis module will introduce principles of paediatric cardiology and cardiac intensive care. Over the course of the week, we will discuss cardiac anatomy and physiology, before moving on to post-natal management of cardiac disease, and subsequent management at specialist centres from the perspectives of the cardiologist, the anaesthetic and surgical teams, as well as the cardiac intensive care team. We will also spend some time looking at arrhythmia, pulmonary hypertension and heart failure, with a focus on underlying pathophysiology and management strategies (including mechanical circulatory support).\\nYou will also critically review literature and latest advancements in the field, and present this in a poster with an oral session.\\nLearning objectives and outcomes\\nAfter taking this module, you will be able to:\\nDescribe the underlying physiology & anatomy of paediatric cardiac disease.\\nUnderstand the principles of management – both surgical and medical.\\nDescribe and suggest management strategies for arrhythmia\\nUnderstand the pathophysiology of pulmonary hypertension and heart failure\\nDescribe management strategies for the above.\\n\\nWho is this module for?\\n\\nThis is a core module for the MSc Paediatrics and Child Health: Intensive Care and an optional module for all other MSc Paediatric and Child Health Pathways, aimed at those with a genuine interest in cardiology and cardiac critical care.\\nTeaching and Learning Methods\\nYou will receive 5 days of interactive online lectures/workshops, which will supplement learning through self-directed study.\\n\\nAssessment\\n\\nYou will need to create a poster and up to date literature review on a topic relevant to the module. You will also be assessed via oral presentation of the topic to the examiners and student group.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Conflict of Laws (LAWS0034) \\n Knowledge of the Conflict of Laws (also known as Private International Law) is essential for any lawyer who aspires to work in any area of practice that transcends national frontiers, whether as a specialist in dispute resolution or in advisory work. London is one of the leading centres for international commercial dispute resolution, and most of the commercial disputes heard in London involve foreign parties, so Conflict of Laws rules are particularly central to the work of the English commercial courts. It is a fascinating area of the law, and one of enormous practical importance as legal relationships and disputes increasingly cross borders, but also one of the most intellectually demanding.\\nYou will deal principally with three separate questions which may arise in cross-border civil and commercial litigation:\\njurisdiction, the question of which court may hear a dispute;\\napplicable law, the question of which law or laws a court will apply to resolve the dispute;\\nthe recognition and enforcement of foreign judgments.\\nThe focus of this module is on the rules and principles which apply to resolve these questions as they arise in civil and commercial disputes with an international element before the English courts. You will also examine the anti-suit injunction, which is one of the key orders which the English courts may make to protect their jurisdiction.\\nThe following are some examples of Conflict of Laws problems that are drawn from a selection of the leading cases that you will cover in this module:\\nCan workers suffering from exposure to asbestos in a mine in South Africa bring their personal injury claims before an English court against an English company that held shares in the South African company that operated the mines?\\nCan an English bank that is facing anti-trust proceedings in the United States obtain an injunction from an English court to restrain the party bringing the proceedings in circumstances where the bank never had a corporate presence in the United States and the transactions at the centre of the anti-trust proceedings were executed in England and governed by English law?\\nA Maltese resident suffers personal injuries in a motor accident in Malta. The accident was caused by the negligence of an English resident on vacation in Malta. Under Maltese law, an accident victim cannot claim damages for pain and suffering, whereas under English law a victim can. The Maltese resident sues the English resident in an English court. Can the Maltese resident claim damages for pain and suffering?\\nFollowing the Iraqi invasion of Kuwait, civil aircraft belonging to Kuwait Airways were seized and removed to Iraq. Iraqi legislation was then passed to transfer the aircraft to Iraqi Airways. Kuwait Airways brings proceedings against Iraqi Airways before an English court for wrongful interference. In determining the owner of the aircraft, should the English court give effect to the Iraqi legislation insofar as the aircraft was situated in Iraq when the legislation was enacted?'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ucl_data[0][590]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDG ID: 16, SDG: Peace, Justice, and Strong Institutions\n",
      "SDG ID: 8, SDG: Decent Work and Economic Growth\n"
     ]
    }
   ],
   "source": [
    "for label in ucl_data[1][590]:\n",
    "    print(f'SDG ID: {label+1}, SDG: {parse_sdg_id(label)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDG ID: 13, SDG: Climate Action\n",
      "SDG ID: 9, SDG: Industry, Innovation, and Infrastructure\n"
     ]
    }
   ],
   "source": [
    "predictions = bert_multilabel.predict(ucl_data[0][590])\n",
    "predictions = bert_multilabel.parse_predictions(\n",
    "    predictions,\n",
    "    top_k=16,\n",
    "    threshold=0.7\n",
    ")\n",
    "\n",
    "for prediction in predictions[0]:\n",
    "    print(f'SDG ID: {prediction+1}, SDG: {parse_sdg_id(prediction)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "args = torch.load('./development/weights/Bert-5/checkpoint-1824/training_args.bin')\n",
    "args"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdg_tool",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
